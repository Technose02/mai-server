{
    "env": {
        "GGML_CUDA_ENABLE_UNIFIED_MEMORY" : "1"
    },
    "alias" : "qwen3-vl-30b-a3b-thinking",
    "model-path" : "/model_data/huggingface/unsloth/Qwen3-VL-30B-A3B-Thinking-GGUF/BF16/Qwen3-VL-30B-A3B-Thinking-BF16-00001-of-00002.gguf",
    "n-gpu-layers" : 99,
    "jinja" : true,
    "top-p": 0.95,
    "top-k": 20,
    "temp": 1.0,
    "min-p": 0.0,
    "flash-attn": "on",
    "ctx-size" : 131072,
    "presence-penalty": 0.0
}
