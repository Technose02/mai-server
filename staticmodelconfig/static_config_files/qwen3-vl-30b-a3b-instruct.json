{
  "alias": "qwen3-vl-30b-a3b-instruct",
  "model-path": "/model_data/huggingface/unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF/BF16/Qwen3-VL-30B-A3B-Instruct-BF16-00001-of-00002.gguf",
  "max-ctx-size": 131072,
  "vocab-type": 2,
  "n-vocab": 131072,
  "n-ctx-train": 393216,
  "n-embd": 5120,
  "n-params": 23572403200,
  "size": 28983971840,
  "capabilities": [
    "completion",
    "multimodal"
  ],
  "mmproj-path": "/model_data/huggingface/unsloth/Qwen3-VL-30B-A3B-Instruct-GGUF/mmproj-BF16.gguf",
  "n-gpu-layers": 99,
  "flash-attn": "on",
  "temp": 0.7,
  "presence-penalty": 1.5,
  "min-p": 0.0,
  "top-k": 20,
  "top-p": 0.8,
  "jinja": true
}