{
  "alias": "qwen3-next-80b-a3b-thinking",
  "model-path": "/model_data/huggingface/unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF/Q8_0/Qwen3-Next-80B-A3B-Thinking-Q8_0-00001-of-00002.gguf",
  "max-ctx-size": 200000,
  "vocab-type": 2,
  "n-vocab": 151936,
  "n-ctx-train": 262144,
  "n-embd": 2048,
  "n-params": 79674391296,
  "size": 84806069248,
  "capabilities": [
    "completion"
  ],
  "n-gpu-layers": 99,
  "flash-attn": "on",
  "batch-size": 512,
  "ubatch-size": 128,
  "temp": 0.6,
  "presence-penalty": 0.0,
  "min-p": 0.0,
  "top-k": 20,
  "top-p": 0.95,
  "jinja": true,
  "no-mmap": true
}